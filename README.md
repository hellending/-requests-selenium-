# -requests-selenium-
两个python爬虫，一个微博的，一个天眼查的
selenium主要是用来登录的，两个网站要获取客户要求的信息都需要登录具体的账号，而登录时两个网站都需要面对验证码的问题，
如果是简单的输入类型验证码，github可以提供强大的有用的解码的机器学习程序，但是遗憾的是，微博采用的是短信验证码，天眼查使用的是拖拽类型
验证码，没有不错的解决方法，只能通过selenium+ chromedriver的方式强行通过人工手动过过验证码转换。
登录之后基本就是要求库进行正常的网页爬取，微博原网页是通过大量的js渲染的，源代码很乱，所以采用re库的正则方式进行数据采集。
而天眼查的的网页源代码相对工整，我们就采用xpth进行数据采集。

之所以没有采用多线程分布式爬虫，主要是由于我们都是账号登录进行爬取，手头没有多余的账号可以浪，一旦被封了就完了。
客户对于速度的要求也不高，所以尽量以节省成本和工作量的方式进行问题解决
